{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Text_PreProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "9f9fm9CLqlLC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- Normalization"
      ],
      "metadata": {
        "id": "i_F4WrzzosgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I like my brother. I like my sister. you like my brother!. \\\n",
        "Do you like my brother?\"\n",
        "# Lower all words in text\n",
        "text_normalized = text.lower()\n",
        "print(text_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd3Ft8tro259",
        "outputId": "78e44251-a6e3-4bce-f355-30d3313e73db"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i like my brother. i like my sister. you like my brother!. do you like my brother?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Tokenization"
      ],
      "metadata": {
        "id": "-qd3s4rlpVQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split input text into sentences\n",
        "sentences = text_normalized.split('. ')\n",
        "print(sentences)\n",
        "\n",
        "# Create keras Tokenizer object\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "\n",
        "# Feed the list of sentences to the tokenizer\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Print words and their corresponding number\n",
        "print(tokenizer.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkIZSf97pX0e",
        "outputId": "e690c66e-ec32-46ec-99e3-79c197be9dcb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i like my brother', 'i like my sister', 'you like my brother!', 'do you like my brother?']\n",
            "{'like': 1, 'my': 2, 'brother': 3, 'i': 4, 'you': 5, 'sister': 6, 'do': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Sequencing"
      ],
      "metadata": {
        "id": "JlYNRacw0Ren"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list of strings to list of numerical vectors\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZamVIZX70afH",
        "outputId": "7a136751-2d3e-4b9b-89a7-277bd1a21416"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 1, 2, 3], [4, 1, 2, 6], [5, 1, 2, 3], [7, 5, 1, 2, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-Padding\n",
        "# padding, truncating: pre or post\n",
        "padded = pad_sequences(sequences, padding='post',\n",
        "                       maxlen=10, truncating='post')\n",
        "\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4YMh84p2CWV",
        "outputId": "6a84f573-59e4-4093-ec9b-9b4e8a3cca5d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 1 2 3 0 0 0 0 0 0]\n",
            " [4 1 2 6 0 0 0 0 0 0]\n",
            " [5 1 2 3 0 0 0 0 0 0]\n",
            " [7 5 1 2 3 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "35cejs3137Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = [\"I like my mother\",\n",
        "                 \"The weather is good\"]\n",
        "\n",
        "# Define Out-of-vocabulary (oov) token for unseen words\n",
        "tokenizer = Tokenizer(num_words=100, oov_token='<oov>')\n",
        "\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentence)\n",
        "print(test_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ymYHH4u361X",
        "outputId": "f0bccee2-0344-421c-b37a-ba260381775a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<oov>': 1, 'like': 2, 'my': 3, 'brother': 4, 'i': 5, 'you': 6, 'sister': 7, 'do': 8}\n",
            "[[5, 2, 3, 1], [1, 1, 1, 1]]\n"
          ]
        }
      ]
    }
  ]
}